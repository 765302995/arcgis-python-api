{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information extraction from Cheshire Fire & Rescue reports using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import spacy\n",
    "from arcgis.learn import prepare_data, EntityRecognizer\n",
    "import pandas as pd\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.raster.functions import colormap\n",
    "from arcgis.geocoding import batch_geocode\n",
    "from word2number import w2n\n",
    "from datetime import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis = GIS(profile='your_online_profile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Data preparation involves splitting the data into training and validation sets, creating the necessary data structures for loading data into the model and so on. The prepare_data() method can directly read the training samples in one of the above specified formats and automate the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(\"file.json\", dataset_type='ner_json',class_mapping={'address_tag':'Address'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The show_batch() method can be used to visualize the training samples, along with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "First we will create the model using `EntityRecognizer` class and passing it the data object.\n",
    "Training the model is an iterative process. We can train the model using its fit() method till the validation loss (or error rate) continues to go down with each training pass also known as epoch. This is indicative of the model learning the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = EntityRecognizer(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner.fit(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate results \n",
    "Now we have the trained model, let's look at how the model perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load trained models \n",
    "Once you are satisfied with the model, you can save it using the save() method. This creates an Esri Model Definition (EMD file) that can be used for inferencing on new data. Saved models can also be loaded back using the load() method. load() method takes the path to the emd file as a required argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner.save('fire_30epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner.load(r'./models/fire_30epoch/fire_30a.emd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference \n",
    "Now we can use the trained model to extract entities from new text documents using extract_entities() function. Just need to pass the folder path of where new text document are located"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Colorize the Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def color_gen():    \n",
    "    random_number = random.randint(16777215//2,16777215)\n",
    "    hex_number = format(random_number, 'x')\n",
    "    hex_number = '#' + hex_number\n",
    "    return hex_number\n",
    "\n",
    "colors = {ent.upper():color_gen() for ent in ner.entities}\n",
    "options = {\"ents\":[ent.upper() for ent in ner.entities], \"colors\":colors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filenames=os.listdir('reports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display a Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=f'reports/{random.choice(filenames)}'\n",
    "with open(filename,'r') as file:\n",
    "    txt=file.read()\n",
    "\n",
    "doc1 = ner.model(txt.replace('\\n',' '))\n",
    "spacy.displacy.render(doc1,jupyter=True, style='ent',options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Entities from Other Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ner.extract_entities('reports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post process results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Data Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def convert_number(x):    \n",
    "    try:        \n",
    "        number=w2n.word_to_num(x) \n",
    "    except:\n",
    "        number=0\n",
    "    return number   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def convert_date(x):    \n",
    "    try:        \n",
    "        date=datetime.strptime(x,'%d/%m/%Y - %H:%M') \n",
    "    except:\n",
    "        date=datetime.strptime('01/01/1970 - 00:00','%d/%m/%Y - %H:%M')\n",
    "    return date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results['Number_of_Engines']=results['Number_of_Engines'].apply(lambda x: convert_number(x))\n",
    "\n",
    "results['Date_and_Time']=results['Date_and_Time'].apply(lambda x: convert_date(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geocode and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_locations(df,  address_col, Region='',Country='',prob=0.8):\n",
    "    processed_df=df.copy(deep=True)\n",
    "    #creating address with city and region\n",
    "    add_miner = processed_df[address_col].apply(lambda x: x+f', {Region}, {Country}') \n",
    "    chunk_size = 200\n",
    "    chunks = len(processed_df[address_col])//chunk_size+1\n",
    "    batch = list()\n",
    "    for i in range(chunks):\n",
    "        batch.extend(batch_geocode(list(add_miner.iloc[chunk_size*i:chunk_size*(i+1)]),source_country=Country))\n",
    "    batch_geo_codes = []\n",
    "    for i,item in enumerate(batch):\n",
    "        if isinstance(item,dict):\n",
    "            if (item['score']>(prob*10) and \n",
    "                    item['address']!= f'{Region}, {Country}'):\n",
    "                batch_geo_codes.append(item['location'])\n",
    "            else:\n",
    "                batch_geo_codes.append('')    \n",
    "        else:\n",
    "            batch_geo_codes.append('') \n",
    "    processed_df['geo_codes'] = batch_geo_codes    \n",
    "    return processed_df\n",
    "\n",
    "def prepare_sdf(processed_df):\n",
    "    processed_df['geo_codes_x'] = 'x'\n",
    "    processed_df['geo_codes_y'] = 'y'\n",
    "    for i,geo_code in processed_df['geo_codes'].iteritems():\n",
    "        if geo_code == '': \n",
    "            processed_df.drop(i,inplace=True) #dropping rows with empty location\n",
    "        else:\n",
    "            processed_df['geo_codes_x'].loc[i]=geo_code.get('x')\n",
    "            processed_df['geo_codes_y'].loc[i]=geo_code.get('y')\n",
    "    \n",
    "    sdf = processed_df.reset_index(drop=True)\n",
    "    sdf['geo_x_y'] = sdf['geo_codes_x'].astype('str') + ',' +sdf['geo_codes_y'].astype('str')\n",
    "    sdf = pd.DataFrame.spatial.from_df(sdf, address_column='geo_x_y') #adding geometry to the dataframe\n",
    "    sdf.drop(['geo_codes_x','geo_codes_y','geo_x_y','geo_codes'],axis=1,inplace=True) #dropping redundant columns\n",
    "    return sdf\n",
    "def publish_to_feature(df, gis, layer_title:str, tags:str,  \n",
    "                       Region:str,Country:str, address_col:str,prob:float=0.8):\n",
    "    processed_df = geocode_locations(df, address_col, Region, Country,prob)\n",
    "    sdf = prepare_sdf(processed_df)\n",
    "#     return sdf\n",
    "    try:        \n",
    "        layer = sdf.spatial.to_featurelayer(layer_title, gis,tags) \n",
    "    except:\n",
    "        layer = sdf.spatial.to_featurelayer(layer_title, gis, tags)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Publish Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take few minutes to run\n",
    "fire_report = publish_to_feature(results, gis,  layer_title='Cheshire Fire & Rescue Service Incident Reports Test', \n",
    "                                tags='nlp,fire',\n",
    "                                Region='Cheshire',Country='England',\n",
    "                                prob=0.9,address_col='Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "gis = GIS(profile='your_online_profile')\n",
    "gis.content.get(\"40d1ec92432d4828a345000c2641e52c\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
